{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f842639e-ee6a-437a-86bf-3c9ad028d096",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CABECALHO"
    }
   },
   "outputs": [],
   "source": [
    "## NOTEBOOK DESENVOLVIDO PARA EXTRAIR, TRATAR E TESTAR DADOS FAKE, SE 'OK' OS DADOS SÂO ESCRITOS 'DADOS_FAKE.ASSO_CONTA_MOVI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe260c3-9230-4a01-aa93-f18251cffeba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "INSTALACOES"
    }
   },
   "outputs": [],
   "source": [
    "## CONEXOES\n",
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c95434-d9a3-47cd-8d98-f0411f38c679",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "IMPORTACOES"
    }
   },
   "outputs": [],
   "source": [
    "## CONEXOES BANCOS\n",
    "import psycopg2\n",
    "from pymongo import MongoClient\n",
    "\n",
    "## TRATAMENTOS E AJUSTES\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import regexp_replace, udf, when, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2845636-5a72-4355-9a30-9f3c6418f569",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SECRETS DATABRICKS"
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/orafaelrp@gmail.com/desafio_tecnico/secrets_databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67e7b012-9c81-4038-8643-e25850fae1ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "VARIAVEIS"
    }
   },
   "outputs": [],
   "source": [
    "## POSTGRES\n",
    "post_link = 'https://us-east-1.console.aws.amazon.com/rds/home?region=us-east-1#database:id=database-1;is-cluster=false'\n",
    "post_user = dbutils.secrets.get(scope=\"db_secrets\", key=\"postgres_user\")\n",
    "post_senha = dbutils.secrets.get(scope=\"db_secrets\", key=\"postgres_password\")\n",
    "post_db = 'postgres_ingestao'\n",
    "post_host = 'database-1.ccv4kogyqnja.us-east-1.rds.amazonaws.com'\n",
    "\n",
    "## MONGODB\n",
    "mongo_link = 'https://cloud.mongodb.com/v2/68efdc7fc3401e1005c111c5#/clusters'\n",
    "mongo_user = dbutils.secrets.get(scope=\"db_secrets\", key=\"mongo_user\")\n",
    "mongo_password = dbutils.secrets.get(scope=\"db_secrets\", key=\"mongo_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c05d94f7-937a-470e-9eff-c9e9aadfdc23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Coleta PostGres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d87eec2f-5139-4dd9-bd77-55a476c62962",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CONEXAO POSTGRES"
    }
   },
   "outputs": [],
   "source": [
    "## CONEXAO COM O BANCO\n",
    "connection = psycopg2.connect(\n",
    "    host=post_host,\n",
    "    database=post_db,\n",
    "    user=post_user,\n",
    "    password=post_senha\n",
    ")\n",
    "print(\"Conexao realizada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d28305bd-906c-4361-962e-121940e95cdc",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760656978771}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "TEMP CONTA"
    }
   },
   "outputs": [],
   "source": [
    "## INICIA EXTRACAO DOS DADOS POSTGRES CONTA\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM CONTA\")\n",
    "result = cursor.fetchall()\n",
    "\n",
    "## AJUSTE DE NOMENCLATURA COLUNA\n",
    "col_names = [desc[0] for desc in cursor.description]\n",
    "df_result = pd.DataFrame(result, columns=col_names)\n",
    "df_conta = spark.createDataFrame(df_result)\n",
    "\n",
    "## MASCARAMENTO CPF/CNPJ\n",
    "def mascarar_parcial(dado, visivel_inicio=3, visivel_fim=2, caractere_mascara='X'):\n",
    "    if dado is None:\n",
    "        return None\n",
    "    tamanho = len(dado)\n",
    "    if tamanho <= visivel_inicio + visivel_fim:\n",
    "        return dado\n",
    "    parte_mascarada = caractere_mascara * (tamanho - visivel_inicio - visivel_fim)\n",
    "    return dado[:visivel_inicio] + parte_mascarada + dado[-visivel_fim:]\n",
    "\n",
    "mascarar_parcial_udf = udf(mascarar_parcial, StringType())\n",
    "\n",
    "df_conta = df_conta.withColumn(\"id_associado\", regexp_replace(\"id_associado\", r'[./-]', '')) \\\n",
    "    .withColumn(\"id_associado\", mascarar_parcial_udf(\"id_associado\")) \\\n",
    "    .withColumn(\"tp_pessoa\", \n",
    "                when((df_conta[\"id_associado\"].isNotNull()) & (length(df_conta[\"id_associado\"]) > 11), \"PJ\")\n",
    "                .otherwise(\"PF\")\n",
    "               )\n",
    "    \n",
    "## CRIANDO A TEMP VIEW\n",
    "df_conta.createOrReplaceTempView(\"CONTA\")\n",
    "\n",
    "## AMOSTRA\n",
    "display(df_conta.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c7dcd11-9dd2-4a71-a46b-8628ce61be8f",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"email\":246},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760656699700}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "TEMP ASSOCIADO"
    }
   },
   "outputs": [],
   "source": [
    "## INICIA EXTRACAO DOS DADOS POSTGRES ASSOCIADO\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM ASSOCIADO\")\n",
    "result = cursor.fetchall()\n",
    "\n",
    "## AJUSTE DE NOMENCLATURA COLUNA\n",
    "col_names = [desc[0] for desc in cursor.description]\n",
    "df_result = pd.DataFrame(result, columns=col_names)\n",
    "df_asso = spark.createDataFrame(df_result)\n",
    "\n",
    "\n",
    "## MASCARAMENTO EMAIL\n",
    "def mascarar_email(email, visivel_inicio=4, visivel_fim=4, caractere_mascara='*'):\n",
    "    if email is None or '@' not in email:\n",
    "        return email\n",
    "    username, domain = email.split('@', 1)\n",
    "    if len(username) <= visivel_inicio:\n",
    "        masked_username = username\n",
    "    else:\n",
    "        parte_mascarada = caractere_mascara * (len(username) - visivel_inicio)\n",
    "        masked_username = username[:visivel_inicio] + parte_mascarada\n",
    "    if len(domain) <= visivel_fim:\n",
    "        masked_domain = domain\n",
    "    else:\n",
    "        parte_mascarada_dom = caractere_mascara * (len(domain) - visivel_fim)\n",
    "        masked_domain = parte_mascarada_dom + domain[-visivel_fim:]\n",
    "    return masked_username + '@' + masked_domain\n",
    "\n",
    "mascarar_email_udf = udf(mascarar_email, StringType())\n",
    "\n",
    "df_asso = df_asso.withColumn(\"email\", mascarar_email_udf(\"email\"))\n",
    "\n",
    "## CRIANDO A TEMP VIEW\n",
    "df_asso.createOrReplaceTempView(\"ASSOCIADO\")\n",
    "\n",
    "## AMOSTRA\n",
    "display(df_asso.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dce5825-fc27-4753-826e-c5a622759c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Coleta MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e35a689c-954d-4935-a6af-1357aa22c701",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CONEXAO MONGO"
    }
   },
   "outputs": [],
   "source": [
    "## CONEXAO COM O BANCO\n",
    "uri = f\"mongodb://{mongo_user}:{mongo_password}@ac-d4sizdx-shard-00-00.4vaxogk.mongodb.net:27017,ac-d4sizdx-shard-00-01.4vaxogk.mongodb.net:27017,ac-d4sizdx-shard-00-02.4vaxogk.mongodb.net:27017/?ssl=true&replicaSet=atlas-9q2wob-shard-0&authSource=admin&retryWrites=true&w=majority&appName=mongo1\"\n",
    "\n",
    "## CRIA O CLIENT MONGO\n",
    "client = MongoClient(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4477bf4-c61d-4d97-a23c-40b19e8a1975",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"_id\":236},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760658081497}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "TEMP MOVIMENTO"
    }
   },
   "outputs": [],
   "source": [
    "## ACESSA COLECAO\n",
    "db = client['ingestao_desafio_engenharia']\n",
    "collection = db['movimento']\n",
    "\n",
    "## TRAZ TODOS OS DOCUMENTOS DA COLECAO\n",
    "docs = [{**doc, '_id': str(doc['_id'])} for doc in collection.find()]\n",
    "df_result = pd.DataFrame(docs)\n",
    "df_movimento = spark.createDataFrame(df_result)\n",
    "\n",
    "## MASCARAMENTO CARTAO\n",
    "def mascarar_parcial(dado, visivel_inicio=6, visivel_fim=4, caractere_mascara='X'):\n",
    "    if dado is None:\n",
    "        return None\n",
    "    tamanho = len(dado)\n",
    "    if tamanho <= visivel_inicio + visivel_fim:\n",
    "        return dado\n",
    "    parte_mascarada = caractere_mascara * (tamanho - visivel_inicio - visivel_fim)\n",
    "    return dado[:visivel_inicio] + parte_mascarada + dado[-visivel_fim:]\n",
    "\n",
    "mascarar_parcial_udf = udf(mascarar_parcial, StringType())\n",
    "\n",
    "df_movimento = df_movimento.withColumn(\"cartao_ficticio\", mascarar_parcial_udf(\"cartao_ficticio\"))\n",
    "\n",
    "## CRIANDO A TEMP VIEW\n",
    "df_movimento.createOrReplaceTempView(\"MOVIMENTO\")\n",
    "\n",
    "## AMOSTRA\n",
    "display(df_movimento.limit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "043c1279-1cb0-426a-a3f1-bd628ff5fa3d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TEMP ASSO_CONTA_MOVI"
    }
   },
   "outputs": [],
   "source": [
    "df_asso_conta_movi = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    MOVI.id AS id_pk,\n",
    "    MOVI.id_conta,\n",
    "    MOVI.tipo_transacao,\n",
    "    MOVI.des_transacao,\n",
    "    MOVI.vlr_transacao,\n",
    "    MOVI.data_movimento AS dt_transacao,\n",
    "    MOVI.cartao_ficticio,\n",
    "    ASSO.nome,\n",
    "    ASSO.sobrenome,\n",
    "    ASSO.idade,\n",
    "    ASSO.email,\n",
    "    CONTA.id_associado AS num_cpf_cnpj,\n",
    "    CONTA.tp_pessoa,\n",
    "    CONTA.data_criacao AS dt_criacao_conta,\n",
    "    MD5(CONCAT(MOVI.id, MOVI.id_conta, MOVI.tipo_transacao, MOVI.des_transacao, MOVI.vlr_transacao, MOVI.data_movimento, MOVI.cartao_ficticio)) AS UNIQUE_ID\n",
    "FROM MOVIMENTO MOVI\n",
    "LEFT JOIN ASSOCIADO ASSO \n",
    "    ON MOVI.id = ASSO.id\n",
    "LEFT JOIN CONTA CONTA \n",
    "    ON MOVI.id = CONTA.id\n",
    "\"\"\")\n",
    "\n",
    "## CRIA TEMP VIEW PARA TESTES UNITARIOS\n",
    "df_asso_conta_movi.createOrReplaceTempView(\"ASSO_CONTA_MOVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d9dbb7-76e7-40fc-9460-8000b5cae9cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TESTES UNITARIOS"
    }
   },
   "outputs": [],
   "source": [
    "## EXECUTANDO TESTES UNITÁRIOS NO OBJETO\n",
    "testes_unitarios = None\n",
    "try:\n",
    "    ## VERIFICA SE A TABELA EXISTE\n",
    "    teste_status = \"TABELA NAO EXISTE\"\n",
    "    df_existe = spark.sql(\"\"\"\n",
    "        SELECT COUNT(*) AS tabela_existe\n",
    "        FROM ASSO_CONTA_MOVI\n",
    "    \"\"\")\n",
    "    if df_existe.collect()[0][\"tabela_existe\"] < 1:\n",
    "        raise Exception()\n",
    "    else:\n",
    "\n",
    "        ## VERIFICA SE ID_MOVIMENTACAO TEM VALORES NULOS\n",
    "        teste_status = \"ID_PK TEM VALORES NULL\"\n",
    "        df_id_nulos = spark.sql(\"\"\"\n",
    "            SELECT COUNT(*) AS df_id_nulos\n",
    "            FROM ASSO_CONTA_MOVI\n",
    "            WHERE id_pk IS NULL\n",
    "        \"\"\")\n",
    "        if df_id_nulos.collect()[0][\"df_id_nulos\"] > 0:\n",
    "            raise Exception()\n",
    "        else:\n",
    "\n",
    "            ## VERIFICA SE OS VALORES SÂO NUMERICOS\n",
    "            teste_status = \"VLR_TRANSACAO TEM VALORES TIPO TEXTO\"\n",
    "            df_vlr_transacao_nao_numerico = spark.sql(\"\"\"\n",
    "                SELECT COUNT(*) AS vlr_transacao_nao_numerico\n",
    "                FROM ASSO_CONTA_MOVI\n",
    "                WHERE TRY_CAST(vlr_transacao AS DOUBLE) IS NULL AND vlr_transacao IS NOT NULL\n",
    "            \"\"\")\n",
    "            if df_vlr_transacao_nao_numerico.collect()[0][\"vlr_transacao_nao_numerico\"] > 0:\n",
    "                raise Exception()\n",
    "            else:\n",
    "\n",
    "                ## VERIFICA SE EXISTE VALORES NEGATIVOS\n",
    "                teste_status = \"VLR_TRANSACAO TEM VALORES NEGATIVOS\"\n",
    "                df_vlr_transacao_negativos = spark.sql(\"\"\"\n",
    "                    SELECT COUNT(*) AS vlr_transacao_negativos\n",
    "                    FROM ASSO_CONTA_MOVI\n",
    "                    WHERE TRY_CAST(vlr_transacao AS DOUBLE) < 0\n",
    "                \"\"\")\n",
    "                if (df_vlr_transacao_negativos.collect()[0][\"vlr_transacao_negativos\"]) > 0:\n",
    "                    raise Exception()\n",
    "                else:\n",
    "\n",
    "                    ## VERIFICA SE A TABELA REGISTRA DATA FUTURA\n",
    "                    teste_status = \"TABELA COM DATA FUTURA\"\n",
    "                    df_transacoes_futuras = spark.sql(\"\"\"\n",
    "                        SELECT COUNT(*) AS transacoes_futuras\n",
    "                        FROM ASSO_CONTA_MOVI\n",
    "                        WHERE TO_DATE(DT_TRANSACAO) > CURRENT_DATE()\n",
    "                    \"\"\")\n",
    "                    if df_transacoes_futuras.collect()[0][\"transacoes_futuras\"] > 0:\n",
    "                        raise Exception()\n",
    "                    else:\n",
    "                        \n",
    "                        ## VERIFICA SE TODOS OS EMAILS TEM @\n",
    "                        teste_status = \"EMAIL SEM @\"\n",
    "                        df_emails_invalidos = spark.sql(\"\"\"\n",
    "                            SELECT COUNT(*) AS emails_invalidos\n",
    "                            FROM ASSO_CONTA_MOVI\n",
    "                            WHERE EMAIL NOT LIKE '%@%'\n",
    "                        \"\"\")\n",
    "                        if df_emails_invalidos.collect()[0][\"emails_invalidos\"] > 0:\n",
    "                            raise Exception()\n",
    "                        else:\n",
    "\n",
    "                            ## VERIFICA SE UNIQUE_ID É ÚNICO\n",
    "                            teste_status = \"CONSIDERANDO UNIQUE_ID A TABELA NAO TEM UNICIDADE\"\n",
    "                            df_unique_id_dup = spark.sql(\"\"\"\n",
    "                                SELECT COUNT(*) AS dup_count\n",
    "                                FROM (\n",
    "                                    SELECT UNIQUE_ID, COUNT(*) AS cnt\n",
    "                                    FROM ASSO_CONTA_MOVI\n",
    "                                    GROUP BY UNIQUE_ID\n",
    "                                    HAVING cnt > 1\n",
    "                                ) t\n",
    "                            \"\"\")\n",
    "                            if df_unique_id_dup.collect()[0][\"dup_count\"] > 0:\n",
    "                                raise Exception()\n",
    "                            else:\n",
    "                                testes_unitarios = \"OK\"                                \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    testes_unitarios = \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8242abd1-6e58-4876-8afc-897b8908802c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CRIACAO E EXPORTACAO"
    }
   },
   "outputs": [],
   "source": [
    "## EXPORTANDO DADOS EM FORMATO DELTA E PARQUET\n",
    "if testes_unitarios == \"OK\":\n",
    "\n",
    "    print(f\"Objeto aprovado em testes unitarios\")\n",
    "\n",
    "    ## ESCREVENDO OBJETO FINAL\n",
    "    df_asso_conta_movi.write.mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .saveAsTable(\"dados_fake.asso_conta_movi\")\n",
    "\n",
    "    ## COMENTANDO OBJETO FINAL\n",
    "    spark.sql(\"\"\"\n",
    "    COMMENT ON TABLE dados_fake.asso_conta_movi IS 'Tabela consolidada de movimentações, associados e contas, com dados sensíveis mascarados e identificador único. Registra transações por cartão, enriquecida com informações dos associados.';\n",
    "    \"\"\")\n",
    "\n",
    "    ## COMENTARIOS POR COLUNA\n",
    "    column_comments = [\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.id_pk IS 'Identificador único da tabela movimento'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.id_conta IS 'Registro da conta correta'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.tipo_transacao IS 'Tipo da transação que foi realizada'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.des_transacao IS 'Descrição da transação que foi realizada'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.vlr_transacao IS 'Valor da transação que foi realizada'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.dt_transacao IS 'Data da transação que foi realizada'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.cartao_ficticio IS 'Número do cartão fictício já mascarado'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.nome IS 'Nome do associado'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.sobrenome IS 'Sobrenome do associado'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.idade IS 'Idade do associado'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.email IS 'E‑mail do associado já mascarado'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.tp_pessoa IS 'Tipo de pessoa (PF/PJ)'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.dt_criacao_conta IS 'Data de criação da conta'\"\"\",\n",
    "        \"\"\"COMMENT ON COLUMN dados_fake.asso_conta_movi.unique_id IS 'Coluna concatenando dados da tabela pra garantir unicidade do dado apresentado'\"\"\"\n",
    "    ]\n",
    "\n",
    "    for stmt in column_comments:\n",
    "        spark.sql(stmt)\n",
    "\n",
    "    ## EXPORTANDO DADOS \n",
    "    df_export = spark.table(\"\"\"dados_fake.asso_conta_movi\"\"\")\n",
    "\n",
    "    ## EXPORT TIPO CSV\n",
    "    df_export.write.mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .format(\"csv\")\\\n",
    "        .save(\"/Volumes/workspace/default/desafio_tecnico/export_data//asso_conta_movi.csv\")\n",
    "\n",
    "    ## EXPORT TIPO DELTA\n",
    "    df_export.write.mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .format(\"delta\")\\\n",
    "        .save(\"/Volumes/workspace/default/desafio_tecnico/export_data//asso_conta_movi.delta\")\n",
    "\n",
    "    ## EXPORT TIPO PARQUET\n",
    "    df_export.write.mode(\"overwrite\")\\\n",
    "        .option(\"overwriteSchema\", \"true\")\\\n",
    "        .format(\"parquet\")\\\n",
    "        .save(\"/Volumes/workspace/default/desafio_tecnico/export_data//asso_conta_movi.parquet\")\n",
    "\n",
    "    print(f\"Objeto exportado em formato CSV, DELTA E PARQUET\")\n",
    "else:\n",
    "    print(f\"O objeto não foi aprovado nos testes unitarios: '{teste_status}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc47899-8a0a-4ea6-a903-b443ad3fb817",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"email\":232},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760697874720}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM dados_fake.asso_conta_movi LIMIT 100"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8083885041538141,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dados_extracao_tratamento",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
